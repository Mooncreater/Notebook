
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mooncreater.github.io/Notebook/notes/perfessional/ML/ML/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>机器学习 - 一只烤鱼的笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../fonts/title.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="brown" data-md-color-accent="brown">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="一只烤鱼的笔记" class="md-header__button md-logo" aria-label="一只烤鱼的笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            一只烤鱼的笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              机器学习
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="brown" data-md-color-accent="brown"  aria-label="切换到暗色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到暗色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="brown" data-md-color-accent="brown"  aria-label="切换到亮色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到亮色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Mooncreater/Notebook" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Mooncreater/Notebook
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../.." class="md-tabs__link">
          
  
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../" class="md-tabs__link">
          
  
  
  AI相关

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="一只烤鱼的笔记" class="md-nav__button md-logo" aria-label="一只烤鱼的笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>

    </a>
    一只烤鱼的笔记
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Mooncreater/Notebook" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Mooncreater/Notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Home
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Welcome to MkDocs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Welcome to MkDocs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Welcome to MkDocs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    AI相关
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    AI相关
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    机器学习
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    机器学习
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    机器学习
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../abstruct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    概念
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    基本术语和模型评估
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    线性模型
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    决策树
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    神经网络
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    支持向量机
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    贝叶斯分类器
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    集成方法
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter9/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    聚类
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter10/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    降维与度量学习
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter11/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    特征选择与稀疏学习
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter12/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    半监督学习
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        第一章
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        第二章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第二章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        基本术语和概念学习
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        第三章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第三章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.基本形式
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.回归任务
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.二分类任务
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.多分类任务
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.类别不平衡
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        第四章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第四章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.基本流程：基于树结构来进行预测
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.划分选择
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.划分选择">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.1 概念
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-c45" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.2 \(C4.5\)决策树算法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-cart" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.3 \(CART\)决策树
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.剪枝处理
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.剪枝处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 预剪枝
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 后剪枝
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.连续值与缺失值
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.连续值与缺失值">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 连续值下的处理
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 缺失值处理
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.多变量决策树
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        第五章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第五章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.神经元模型
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.神经元模型">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1概念
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2激活函数
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.感知机与多层网络
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.感知机与多层网络">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.1 感知机
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.2 感知机学习
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.3多层网络
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3bp" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.误差逆传播算法(BP)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.误差逆传播算法(BP)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 概念
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 符号
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 思路
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4 关于单隐层神经元小结论
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-bp" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.5 累计 BP 算法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.6 缓解过拟合
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.其他神经网络
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        第六章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第六章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.间隔与支持向量
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.对偶问题
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.对偶问题">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        拉格朗日乘子法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smo" class="md-nav__link">
    <span class="md-ellipsis">
      
        SMO
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SMO">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        思路：
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.核函数
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.核函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 基本想法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 常见核函数
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.软间隔与正则化
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.软间隔与正则化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-01" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 0/1损失函数
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 正则化
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.支持向量回归
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        第七章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第七章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.基本理论
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.贝叶斯定理
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.极大似然估计
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.极大似然估计">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 什么是似然？
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 怎么计算？
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 拉普拉斯修正
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.半朴素贝叶斯
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        第八章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第八章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.个体与集成
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.个体与集成">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1 串行-Boosting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-adaboost" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2 AdaBoost算法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3 并行-Bagging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.4 Bagging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#15" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.5 随机森林
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.结合策略
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.多样性
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.多样性">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 误差-分歧分解
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      
        第九章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第九章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.性能度量
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.性能度量">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.1 外部指标
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.2 内部指标
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.常见的聚类方法
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.常见的聚类方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 原型聚类
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 原型聚类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#311-k-means-k" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.1 k-means k均值聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.2 学习向量量化
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 密度聚类
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 层次聚类
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      
        第十章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第十章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1k" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.k近邻学习
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.低维嵌入
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.主成分分析
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. 核化线性降维
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.流形学习
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      
        第十一章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第十一章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. 特征选择
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. 特征选择">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1 过滤式选择
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2 包裹式选择
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-l_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3 嵌入式选择与 \(L_1\) 正则化
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.稀疏表示与字典学习
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. 压缩感知
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    <span class="md-ellipsis">
      
        第十二章
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="第十二章">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. 未标记样本
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        2.生成式方法
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3svm" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.半监督SVM
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="_1">机器学习<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">第一章<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>定义: 利用经验改善系统自身性能</p>
<hr />
<h2 id="_3">第二章<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 基本术语和模型评估</h2>

<h4 id="_4">基本术语和概念学习<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<ul>
<li><strong><em>1.经典的机器学习过程</em></strong>：
<img alt="alt text" src="../img/%7B58E8DF85-9B66-4169-BA5D-A22E6F617B9A%7D.png" /></li>
<li>
<p><strong><em>2.术语拓展：</em></strong></p>
<ul>
<li>
<p><strong>数据</strong>：</p>
<table>
<thead>
<tr>
<th>基本术语</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>特征</td>
<td>又称属性，<span class="arithmatex">\(\bold{x} = (x_0,x_1,\cdots,x_{n-1}), x_i\in\Sigma_i\)</span></td>
</tr>
<tr>
<td>属性值</td>
<td>特征的离散取值或连续取值</td>
</tr>
<tr>
<td>样本维度</td>
<td>特征的个数,即<span class="arithmatex">\(n\)</span></td>
</tr>
<tr>
<td>特征张成的空间</td>
<td>属性空间/特征空间/输⼊空间</td>
</tr>
<tr>
<td>标记张成的空间</td>
<td>标记空间/输出空间</td>
</tr>
<tr>
<td>示例/样本</td>
<td>一个对象的输入，示例不含标记</td>
</tr>
<tr>
<td>样例</td>
<td>示例+标记</td>
</tr>
<tr>
<td>- <strong>任务</strong>：</td>
<td></td>
</tr>
<tr>
<td>根据标记的取值情况分为：</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>任务</th>
<th>标记情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>分类</td>
<td>离散值</td>
</tr>
<tr>
<td>回归</td>
<td>连续值</td>
</tr>
<tr>
<td>聚类</td>
<td>空值</td>
</tr>
<tr>
<td>监督学习</td>
<td>所有示例都有标记</td>
</tr>
<tr>
<td>无监督学习</td>
<td>所有示例都没有标记(聚类)</td>
</tr>
</tbody>
</table>
</li>
<li>
<p><strong>目标</strong>：
<span style="background-color: #ffff00">泛化能力</span>(对未来的预测能力)</p>
</li>
</ul>
</li>
<li>
<p><strong><em>3.概念学习</em></strong></p>
</li>
<li>
<p><strong>假设空间</strong>:枚举所有的假设，样本 <span class="arithmatex">\(\bold{x} = (x_0,\cdots,x_{n-1}) \in \bold{V}\)</span> , <span class="arithmatex">\(H = \{ h | h \subset \bold{V}\}\)</span>，也就是对 <span class="arithmatex">\(\bold{x}\)</span> 所有取值的预测函数，包括 <span class="arithmatex">\(\empty\)</span>.</p>
</li>
<li><strong>版本空间</strong>：假设空间的子集，在训练集上全部运行正确,如：<span class="arithmatex">\(h_{色泽 = *,根蒂 = *,敲声 = 浊响}(\bold{x}),\)</span>对于所有的样本<span class="arithmatex">\(\bold{x}\)</span>都能预测正确，那么该<span class="arithmatex">\(h\)</span>属于<span style="background-color: #00ccffff">版本空间</span>。</li>
<li><strong>归纳偏好</strong>：对<span style ="background-color : #00bbffff">非测试集</span>不同预测可能会有不同的结果。</li>
<li><strong>没有免费午餐</strong>：一个算法<span class="arithmatex">\(\xi_a\)</span>如果在某些问题上比另一个算法<span class="arithmatex">\(\xi_b\)</span>好，必然存在另一些问题，<span class="arithmatex">\(\xi_b\)</span>比<span class="arithmatex">\(\xi_a\)</span> 好, 也即没有免费的午餐定理。(总误差与学习算法无关)</li>
<li>
<p><strong><em>4.模型评估与选择</em></strong></p>
<p><strong>4.1 选择模型</strong>：经验性能<span class="arithmatex">\(E\)</span>(历史表现) <span class="arithmatex">\(\approx\)</span> 泛化性能<span class="arithmatex">\(E^*\)</span>(未来表现得不到)</p>
<ul>
<li><strong>经验误差</strong>：也称训练误差，在训练集上的误差</li>
<li><strong>过拟合</strong>：将样本本身特点当做一般性质学习<span class="arithmatex">\(\to\)</span> <span style = "color: #00bbffff">优化目标加正则项</span></li>
<li><strong>欠拟合</strong>：对样本的一般性质没有学好<span class="arithmatex">\(\to\)</span> <span style = "color: #00bbffff">决策树：拓展分支，神经网络：增加训练轮数</span></li>
</ul>
<p><strong>4.2 评估方法</strong>：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>留出法</td>
<td>将数据划分两个互斥集合训练和测试集，保持数据分布一致性和类别比例一致性<span class="arithmatex">\(2:1 \sim 4:1\)</span></td>
</tr>
<tr>
<td>交叉验证法</td>
<td><img alt="alt text" src="../img/%7B52CB25BB-78AF-4B49-B071-89944CBA6474%7D.png" /></td>
</tr>
<tr>
<td>自助法</td>
<td>从<span class="arithmatex">\(D\)</span>中随机有放回取生成<span class="arithmatex">\(D'\)</span></td>
</tr>
<tr>
<td>调参数</td>
<td>对算法的参数进行设定，在验证集上确定参数。训练集：模型训练，验证集：参数调优，测试集：最终评估</td>
</tr>
</tbody>
</table>
<p><strong>4.3 性能度量</strong>：
<strong><em>4.3.1 "混淆矩阵"</em></strong>:</p>
<p><img alt="alt text" src="../img/%7B2E109B9C-582A-484D-9BBB-ED2DB18968A3%7D.png" /></p>
<p><span style="background-color: #00bbffff">查准率<span class="arithmatex">\(P\)</span></span>：所有模型预测的正例中真正正例所占的比例。</p>
<p><span style="background-color: #00bbffff">查全率<span class="arithmatex">\(R\)</span></span>：所有的正例中模型预测为正例的比例。</p>
<p><strong><em>4.3.2 P-R曲线</em></strong>：
<img alt="alt text" src="../img/%7BB1E22EB9-DD03-4C68-B9E0-C79469F9794D%7D.png" /></p>
<p><span style="background-color: #00bbffff">平衡点</span>：查准率= 查全率时的取值，用来度量曲线有交叉的两个分类器的性能，如图中A，B。
<strong><em>4.3.3 <span class="arithmatex">\(F_1\)</span>度量</em></strong>:</p>
<p><span class="arithmatex">\(F_1 = \frac{2 \times P \times R}{P + R}\)</span></p>
<p>更一般的形式<span class="arithmatex">\(F_{\beta}\)</span>：</p>
<p><span class="arithmatex">\(F_{\beta} = \frac{(1 + \beta^2)\times P \times R}{(\beta^2 \times P) + R}\)</span></p>
<table>
<thead>
<tr>
<th><span class="arithmatex">\(\beta\)</span></th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\beta = 1\)</span></td>
<td>标准<span class="arithmatex">\(F_1\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(\beta &gt; 1\)</span></td>
<td>偏重查全率(逃犯信息检索)</td>
</tr>
<tr>
<td><span class="arithmatex">\(\beta &lt; 1\)</span></td>
<td>偏重查准率(商品推荐系统)</td>
</tr>
</tbody>
</table>
<p><strong><em>4.3.4 ROC曲线</em></strong>:</p>
<p>真正例率：<span class="arithmatex">\(\frac{TP}{TP + FN}\)</span>,预测正例中正例占所有正例的比例.</p>
<p>假正例率：<span class="arithmatex">\(\frac{FP}{FP + TN}\)</span>，预测正例中徦例占所有徦例的比例.</p>
<p><img alt="alt text" src="../img/image.png" />
<strong><em>面积大者优，也称 <span style="background-color: #00bbffff">AUC</span>值</em></strong></p>
<p>AUC衡量了样本预测的<span style="background-color: #00bbffff">排序质量</span></p>
<p><strong><em>4.3.5 性能评估</em></strong>:</p>
</li>
</ul>
<hr />
<h2 id="_5">第三章<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 线性模型</h2>

<h4 id="1">1.基本形式<a class="headerlink" href="#1" title="Permanent link">&para;</a></h4>
<p><span class="arithmatex">\(f(\bm{x}) = w_1 x_1 + w_2 x_2 + \cdots + w_d x_d +b\)</span></p>
<p>向量形式：</p>
<p><span class="arithmatex">\(f(\bm{x}) = \bm{w^T}\bm{x} + b\)</span></p>
<h4 id="2">2.回归任务<a class="headerlink" href="#2" title="Permanent link">&para;</a></h4>
<p>单元目标：<span class="arithmatex">\(f(x) = w x_i + b\)</span>,使得：<span class="arithmatex">\(f(x_i) \simeq y_i\)</span></p>
<p>最小化均方误差：<span class="arithmatex">\(E_{(w,b)} = \sum\limits_{i =1}^{m}(y_i - w x_i- b)^2\)</span></p>
<p><strong>多元线性回归：</strong>
<span class="arithmatex">\(f(\bm{x_i}) = \bm{w}^T\bm{x_i} + b\)</span>， 数据有多个属性</p>
<p>数据集 <span class="arithmatex">\(D = \{(\bm{x_1},y_1),(\bm{x_2},y_2),\cdots,(\bm{x_m},y_m)\}\)</span></p>
<p>其中 <span class="arithmatex">\(\bm{x_i} = (x_{i1},x_{i2},\cdots,x_{id}),y_i \in \mathbb{R}\)</span> </p>
<p>令 <span class="arithmatex">\(\bold{X} = \begin{pmatrix}
x_{11} &amp; x_{12} &amp; \cdots&amp; x_{1d} &amp;1 \\
x_{21} &amp; x_{22} &amp; \cdots&amp; x_{2d} &amp; 1\\
\cdots    &amp; \cdots    &amp;\cdots&amp;\cdots. &amp; \cdots\\
x_{m1} &amp;x_{m2} &amp; \cdots&amp; x_{md} &amp; 1
\end{pmatrix}\)</span> <span class="arithmatex">\(= 
\begin{pmatrix}
\bm{x}_1^T &amp; 1\\
\bm{x}_2^T &amp; 1\\
\cdots &amp;\cdots\\
\bm{x}_m^T &amp; 1
\end{pmatrix}\)</span></p>
<p><span class="arithmatex">\(\hat{\bm{w}} = (\bm{w} ; b)\)</span>,则：</p>
<p><span class="arithmatex">\(\bold{f(\bold{X})} = \bold{X} \hat{\bm{w}}\)</span> ，损失函数 <span class="arithmatex">\(E_{\hat{\bm{w}}} = (\bm{y} - \bold{X}\bm{\hat{w}})^T(\bm{y} - \bold{X}\bm{\hat{w}})\)</span></p>
<p>一阶导： <span class="arithmatex">\(\frac{\partial E_{\bm{\hat{w}}}}{\partial \bm{\hat{w}}} = 2 \bold{X} ^T (\bold{X}\bm{\hat{w}} - \bm{y})\)</span>.</p>
<h4 id="3">3.二分类任务<a class="headerlink" href="#3" title="Permanent link">&para;</a></h4>
<p><span class="arithmatex">\(z = \bm{w}^T\bm{x} + b\)</span></p>
<p><span class="arithmatex">\(y = g(z)\)</span>,根据<span class="arithmatex">\(z\)</span>的值来进行分类</p>
<p>单位阶跃函数：</p>
<div class="arithmatex">\[y=
\begin{cases}
0, &amp; \textbf{z &lt; 0}\\
0.5, &amp;\textbf{z = 0}\\
1, &amp;\textbf{z &gt; 0}
\end{cases}\]</div>
<p>替代函数：<span class="arithmatex">\(y = \frac{1}{1 + e^{-z}} = \frac{1}{1 + e^{-(\bm{w}^T\bm{x} + b)} }\)</span>
<img alt="alt text" src="../img/%7B637C236A-26FC-43F4-B3BC-9B6C2B6C8E07%7D.png" /></p>
<p><strong>对数几率</strong>：事件发生的概率比上不发生的概率的对数，即：</p>
<p><span class="arithmatex">\(\ln \frac{p(y=1|\bm{x})}{p(y=0|\bm{x})} = \ln\frac{p(y = 1|\bm{x})}{1-p(y = 1|\bm{x})} = \bm{w}^T\bm{x} +b\)</span></p>
<h4 id="4">4.多分类任务<a class="headerlink" href="#4" title="Permanent link">&para;</a></h4>
<h4 id="5">5.类别不平衡<a class="headerlink" href="#5" title="Permanent link">&para;</a></h4>
<p>即 <span class="arithmatex">\(\frac{y}{1-y} &gt; 1\)</span></p>
<p>将其转化为类别平衡任务</p>
<p><img alt="alt text" src="../img/%7BA9430E93-D6DD-40B6-91C9-5F6FDE0B9553%7D.png" />
<img alt="alt text" src="../img/%7B53E905D5-38D4-4E46-A276-A3D296C86A1E%7D.png" /></p>
<hr />
<h2 id="_6">第四章<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 决策树</h2>

<h4 id="1_1">1.基本流程：基于树结构来进行预测<a class="headerlink" href="#1_1" title="Permanent link">&para;</a></h4>
<p>递归停止条件：</p>
<ol>
<li>
<p>当前节点包含的样本全都属于同一类，全为好瓜或者坏瓜 </p>
</li>
<li>
<p>当前属性集为空，或者所有样本在所有属性上取值相同，即剩下的分类属性没区别，样本的“纹理”都=“清晰”，“脐部”都=“凹陷”</p>
</li>
<li>
<p>当前结点包含的样本集合为空，看其父节点数量最多的类别，好瓜多则该属性下分类标记为好瓜</p>
</li>
</ol>
<h4 id="2_1">2.划分选择<a class="headerlink" href="#2_1" title="Permanent link">&para;</a></h4>
<h5 id="21">2.1 概念<a class="headerlink" href="#21" title="Permanent link">&para;</a></h5>
<p><strong><em>信息熵：</em></strong>  <span class="arithmatex">\(Ent(D) = - \sum\limits_{k=1}^{\mathcal{Y}}p_k\log_2p_k\)</span>
值越小纯度越高，我们希望信息更纯，所以需要最大化减小信息熵</p>
<p><strong><em>信息增益：</em></strong> <span class="arithmatex">\(Gain(D,a) = Ent(D) - \sum\limits_{v=1}^{V} \frac{|D^v|}{|D|}Ent(D^v)\)</span> 
对于属性 <span class="arithmatex">\(a\)</span> 划分产生 <span class="arithmatex">\(V\)</span> 个结点 <span class="arithmatex">\(Ent(D^v)\)</span> 为每个结点的信息熵</p>
<p><strong><em>选择：</em></strong> 每次选择<span style="background-color: #00bbffff; font-weight: normal;">信息增益最大</span>的属性划分</p>
<p><strong><em>缺点：</em></strong> 信息增益指标很明显偏好取值数目多的属性，也就是 <span class="arithmatex">\(V\)</span> 值越大信息增益会偏大</p>
<h5 id="22-c45">2.2 <span class="arithmatex">\(C4.5\)</span>决策树算法<a class="headerlink" href="#22-c45" title="Permanent link">&para;</a></h5>
<p>于是可以考虑规范化，使用"增益率 " <span class="arithmatex">\(Gain\_ratio(D,a) = \frac{Gain(D,a)}{IV(a)}\)</span> , 其中 <span class="arithmatex">\(IV(a) = -\sum\limits_{v=1}^{V}\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}\)</span> </p>
<h5 id="23-cart">2.3 <span class="arithmatex">\(CART\)</span>决策树<a class="headerlink" href="#23-cart" title="Permanent link">&para;</a></h5>
<p><strong>基尼指数:</strong> <span class="arithmatex">\(Gini(D) = \sum\limits_{k=1}^{|\mathcal{Y}|}\sum\limits_{k'\neq k}^{}p_kp_{k'} = 1- \sum\limits_{k=1}^{|\mathcal{Y}|}p_k^2\)</span>
反映了从数据集中随机取两个样本，其类别标记不一致的概率，指数<span style = "background-color: #00bbffff ">越小越纯</span></p>
<p><strong>关于属性<span class="arithmatex">\(a\)</span>的基尼指数定义：</strong><span class="arithmatex">\(Gini\_index(D,a) = \sum\limits_{v=1}^{V}\frac{|D^v|}{|D|}Gini(D^v)\)</span></p>
<h4 id="3_1">3.剪枝处理<a class="headerlink" href="#3_1" title="Permanent link">&para;</a></h4>
<p>为什么剪枝？ </p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 处理决策树过拟合 </li>
</ul>
<p>用留出法预留一部分数据作为"验证集"进行性能评估</p>
<h5 id="31">3.1 预剪枝<a class="headerlink" href="#31" title="Permanent link">&para;</a></h5>
<ol>
<li>针对<u>训练集</u>，根据信息增益准则选择属性进行划分</li>
<li>用<u>验证集</u>计算划分前后精度变化</li>
<li>若提高精度，则划分</li>
</ol>
<h5 id="32">3.2 后剪枝<a class="headerlink" href="#32" title="Permanent link">&para;</a></h5>
<p>先建树后根据剪枝前后验证集精度决定是否剪除</p>
<h4 id="4_1">4.连续值与缺失值<a class="headerlink" href="#4_1" title="Permanent link">&para;</a></h4>
<h5 id="41">4.1 连续值下的处理<a class="headerlink" href="#41" title="Permanent link">&para;</a></h5>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 二分法</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 离散化</li>
</ul>
<p>1.考虑连续属性a在样本集上的n个不同取值，从小到大排列 <span class="arithmatex">\(a^1,a^2,\cdots,a^n\)</span>,基于划分点<span class="arithmatex">\(t\)</span> 可以分为子集<span class="arithmatex">\(D_t^+,D_t^-\)</span>.划分点集合 <span class="arithmatex">\(T_a = \{ \frac{a^i+a^{i+1}}{2}|1 \leq i \leq n-1\}\)</span>,即相邻点的中值集合.</p>
<p>2.考察划分点，选最优：
<span class="arithmatex">\(Gain(D,a) = \max\limits_{t \in T_a}Gain(D,a,t) = \max\limits_{t\in T_a}Ent(D) - \sum\limits_{\lambda \in \{-,+\}}\frac{|D_t^{\lambda|}}{|D|}Ent(D_t^{\lambda})\)</span></p>
<p><span style = "background-color : #00bbffff"> 该属性还可以作为后代结点的划分属性</span>🧐</p>
<h5 id="42">4.2 缺失值处理<a class="headerlink" href="#42" title="Permanent link">&para;</a></h5>
<p>令 <span class="arithmatex">\(\tilde{D}\)</span> 表示 <span class="arithmatex">\(D\)</span> 在属性 <span class="arithmatex">\(a\)</span> 上没有缺失的样.
假设属性 <span class="arithmatex">\(a\)</span> 有 <span class="arithmatex">\(V\)</span> 个取值 <span class="arithmatex">\(\{a^1,a^2,\cdots,a^V\}\)</span>.
<span class="arithmatex">\(\tilde{D}^v\)</span> 表示 <span class="arithmatex">\(\tilde{D}\)</span> 中属性 <span class="arithmatex">\(a\)</span> 取值为 <span class="arithmatex">\(a^v\)</span> 的样本子集.
<span class="arithmatex">\(\tilde{D}_k\)</span> 表示 <span class="arithmatex">\(\tilde{D}\)</span> 中属于第 <span class="arithmatex">\(k\)</span> 类 <span class="arithmatex">\((k = 1,2,\cdots, |\mathcal{Y}|)\)</span> 的样本子集.
假设对每个样本 <span class="arithmatex">\(\bm{x}\)</span> 赋予一个权重 <span class="arithmatex">\(w_{\bm{x}}\)</span> ,定义：
-   无缺失值样本所占比例： <span class="arithmatex">\(\rho = \frac{\sum\limits_{\bm{x}\in \tilde{D}}w_{\bm{x}}}{\sum\limits_{\bm{x}\in D}w_{\bm{x}}}\)</span>
-   无缺失值样本中第 <span class="arithmatex">\(k\)</span> 类所占比例：<span class="arithmatex">\(\tilde{p}_k = \frac{\sum\limits_{\bm{x}\in\tilde{D}_k}w_{\bm{x}}}{\sum\limits_{\bm{x}\in \tilde{D}}w_{\bm{x}}}\)</span>
-   无缺失值样本属性 <span class="arithmatex">\(a\)</span> 上取值 <span class="arithmatex">\(a^v\)</span> 比例：<span class="arithmatex">\(\tilde{r}_v = \frac{\sum\limits_{\bm{x}\in \tilde{D}^v}w_{\bm{x}}}{\sum\limits_{\bm{x}\in\tilde{D}}w_{\bm{x}}}\)</span></p>
<p>信息增益推广计算式：</p>
<div class="arithmatex">\[
Gain(D,a) = \rho \times Gain(\tilde{D},a) = \rho \times \Bigg(Ent(\tilde{D}) - \sum\limits_{v=1}^{V}\tilde{r}_vEnt(\tilde{D}^v) \Bigg)
\]</div>
<p>其中 <span class="arithmatex">\(Ent(\tilde{D}) = - \sum\limits_{k=1}^{|\mathcal{Y}|} \tilde{p}_k\log_2\tilde{p}_k\)</span>.</p>
<p>❇️ 对于属性 <span class="arithmatex">\(a\)</span>  未知的 <span class="arithmatex">\(\bm{x}\)</span> 将其划分到 <span style = "background-color: #00bbffff">所有子结点</span> 中,权重标记为 <span class="arithmatex">\(\tilde{r}_v\cdot w_{\bm{x}}\)</span></p>
<p><span style = "background-color: #bbff00ff">计算增益不考虑无属性，无属性划分按相应概率</span></p>
<h4 id="5_1">5.多变量决策树<a class="headerlink" href="#5_1" title="Permanent link">&para;</a></h4>
<p>非叶节点不再是单个属性而是多对的线性组合 <span class="arithmatex">\(\sum\limits_{i=1}^{d}w_ia_i = t\)</span> 线性分类器.
<img alt="alt text" src="../img/%7BA9696FD3-BF3B-404A-ABAE-C136C41C3941%7D.png" /></p>
<hr />
<h2 id="_7">第五章<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 神经网络</h2>

<h4 id="1_2">1.神经元模型<a class="headerlink" href="#1_2" title="Permanent link">&para;</a></h4>
<h5 id="11">1.1概念<a class="headerlink" href="#11" title="Permanent link">&para;</a></h5>
<p><span class="arithmatex">\(y = f( \sum\limits_{i=1}^{n}w_ix_i - \theta)\)</span>, <span class="arithmatex">\(f\)</span> 为激活函数， <span class="arithmatex">\(\theta\)</span> 为阈值.</p>
<p><img alt="alt text" src="../img/%7BAC904666-000C-44DA-8858-B1C3FAFD31C2%7D.png" /></p>
<h5 id="12">1.2激活函数<a class="headerlink" href="#12" title="Permanent link">&para;</a></h5>
<p><img alt="alt text" src="../img/%7B124B192D-167E-4E35-91F1-C100E9EDF9B8%7D.png" /></p>
<h4 id="2_2">2.感知机与多层网络<a class="headerlink" href="#2_2" title="Permanent link">&para;</a></h4>
<h5 id="21_1">2.1 感知机<a class="headerlink" href="#21_1" title="Permanent link">&para;</a></h5>
<p><span class="arithmatex">\(y = f( \sum\limits_{i=1}^{n}w_ix_i - \theta)\)</span>, 可以容易实现 "与","或","非".
| 逻辑  |  实现  |
|---|----|
|“与” |  <span class="arithmatex">\(w_1 = w_2 = 1, \theta = 2\)</span>  |
|“或”|  <span class="arithmatex">\(w_1 = w_2 = 1, \theta =0.5\)</span>  |
|“非”|  <span class="arithmatex">\(w_1 = -0.6, w_2 = 0, \theta = -0.5\)</span>  |</p>
<p><img alt="alt text" src="../img/%7B649F45C2-DBDD-4448-AD87-C59146BBA21F%7D.png" /> </p>
<h5 id="22">2.2 感知机学习<a class="headerlink" href="#22" title="Permanent link">&para;</a></h5>
<p>训练样例 <span class="arithmatex">\((\bm{x},y)\)</span> ,当前感知机输出 <span class="arithmatex">\(\hat{y}\)</span>.
<span class="arithmatex">\(w_i\)</span> 变化 <span class="arithmatex">\(\Delta w_i = \eta(y - \hat{y})x_i\)</span>, 学习率 <span class="arithmatex">\(\eta \in (0,1)\)</span> .</p>
<h5 id="23">2.3多层网络<a class="headerlink" href="#23" title="Permanent link">&para;</a></h5>
<p>求解非线性问题</p>
<p><img alt="alt text" src="../img/%7BE3917F84-E16B-405A-84A5-A2B5842587FC%7D.png" /></p>
<p>通过学习来调整各层之间的 <span class="arithmatex">\(w\)</span> 和 <span class="arithmatex">\(\theta\)</span>.</p>
<h4 id="3bp">3.误差逆传播算法(BP)<a class="headerlink" href="#3bp" title="Permanent link">&para;</a></h4>
<h5 id="31_1">3.1 概念<a class="headerlink" href="#31_1" title="Permanent link">&para;</a></h5>
<p><img alt="alt text" src="../img/%7B3053BF71-E8FF-4A4E-B9B6-6EEF04727FE7%7D.png" /></p>
<h5 id="32_1">3.2 符号<a class="headerlink" href="#32_1" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>记号</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>训练集 <span class="arithmatex">\(D\)</span></td>
<td><span class="arithmatex">\(D = \{ (\bm{x}_i,y_i)\},\bm{x}_i \in R^d,y_i \in R^l,i = 1,2,\cdots,m\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(\theta_j\)</span></td>
<td>输出层第 <span class="arithmatex">\(j\)</span> 个神经元阈值</td>
</tr>
<tr>
<td><span class="arithmatex">\(\gamma_h\)</span></td>
<td>隐含层第 <span class="arithmatex">\(h\)</span> 个神经元阈值</td>
</tr>
<tr>
<td><span class="arithmatex">\(v_{ih}\)</span></td>
<td>输入层和隐层神经元之间的连接权重</td>
</tr>
<tr>
<td><span class="arithmatex">\(w_{hj}\)</span></td>
<td>隐层和输出层神经元之间的连接权重</td>
</tr>
<tr>
<td><span class="arithmatex">\(b_h\)</span></td>
<td>第 <span class="arithmatex">\(h\)</span> 隐层输出 <span class="arithmatex">\(b_h=f(\alpha_h - \gamma_h)\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(\alpha_h\)</span></td>
<td>第 <span class="arithmatex">\(h\)</span> 隐层输入 <span class="arithmatex">\(\alpha_h=\sum\limits_{i=1}^{d}v_{ih}x_i\)</span></td>
</tr>
<tr>
<td>$\hat{y}_j^k $</td>
<td>第 <span class="arithmatex">\(j\)</span> 输出层输出 <span class="arithmatex">\(\hat{y}_j^k = f(\beta_j - \theta_j)\)</span></td>
</tr>
<tr>
<td><span class="arithmatex">\(\beta_j\)</span></td>
<td>第 <span class="arithmatex">\(j\)</span> 输出层输入 <span class="arithmatex">\(\beta_j=\sum\limits_{i=q}^{d}w_{hj}b_h\)</span></td>
</tr>
</tbody>
</table>
<h5 id="33">3.3 思路<a class="headerlink" href="#33" title="Permanent link">&para;</a></h5>
<p>样例 <span class="arithmatex">\((\bm{x}_k,\bm{y}_k)\)</span>,实际网络输出 <span class="arithmatex">\(\hat{y}_k\)</span>.</p>
<p>误差函数 <span class="arithmatex">\(E_k = \frac{1}{2}\sum\limits_{j=1}^{l}(\hat{y}_j^k - y_j^k)^2\)</span></p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 优化参数 </li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 目标负梯度方向调整参数</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 局部最小</li>
</ul>
<p>给定学习率 <span class="arithmatex">\(\eta\)</span>, 考虑 <span class="arithmatex">\(w_{hj}\)</span> 的优化 <span class="arithmatex">\(\Delta w_{hj}\)</span> <span style = "background-color : #d4ff008a" >"对 <span class="arithmatex">\(E_k\)</span> 求偏导"</span></p>
<p><span class="arithmatex">\(\Delta w_{hj} = - \eta \frac{\partial E_k}{\partial w_{hj}} = -\eta \frac{\partial E_k}{\partial \hat{y}_j^k} \cdot \frac{\partial\hat{y}_j^k}{\partial \beta_j}\cdot \frac{\partial \beta_j}{\partial w_{hj}}\)</span></p>
<h5 id="34">3.4 关于单隐层神经元小结论<a class="headerlink" href="#34" title="Permanent link">&para;</a></h5>
<p><span class="arithmatex">\(b_h = \frac{\partial\beta_j}{\partial w_{hj}}\)</span> </p>
<p><span class="arithmatex">\(g_j = \frac{\partial E_k}{\partial \hat{y}_j^k} \cdot \frac{\partial\hat{y}_j^k}{\partial \beta_j} = (\hat{y}_j^k -y_j^k)\cdot f'(\beta_j -\theta_j)\)</span> <sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> <span class="arithmatex">\(=(\hat{y}_j^k -y_j^k)\cdot \hat{y}_j^k(1-\hat{y}_j^k)\)</span></p>
<p><span class="arithmatex">\(e_h = -\frac{\partial E_k}{\partial b_h}\cdot \frac{\partial b_h}{\partial \alpha_h}= -\sum\limits_{j=1}^{l}\frac{\partial E_k}{\partial \beta_j}\cdot \frac{\partial\beta_j}{\partial b_h}\cdot f'(\alpha_h-\gamma_h) = \sum\limits_{j=1}^{l}g_i w_{hj}b_h (1-b_h)\)</span></p>
<p><span class="arithmatex">\(\Delta w_{hj} = \eta g_j b_h\)</span></p>
<p><span class="arithmatex">\(\Delta \theta_j = -\eta g_j\)</span></p>
<p><span class="arithmatex">\(\Delta v_{ih} = \eta e_h x_i\)</span></p>
<p><span class="arithmatex">\(\Delta \gamma_h = -\eta e_h\)</span></p>
<h5 id="35-bp">3.5 累计 BP 算法<a class="headerlink" href="#35-bp" title="Permanent link">&para;</a></h5>
<p>优化目标是整个训练集累计误差 <span class="arithmatex">\(E = \frac{1}{m} \sum\limits_{k=1}^{m} E_k\)</span>.
读取<u>整个训练集</u>一遍再进行参数更新</p>
<h5 id="36">3.6 缓解过拟合<a class="headerlink" href="#36" title="Permanent link">&para;</a></h5>
<p>早停：若训练误差降低，但验证误差升高，则停止训练
正则化：<span class="arithmatex">\(E = \lambda\frac{1}{m}\sum\limits_{k=1}^{m}E_k +(1-\lambda)\sum\limits_{i}w_i^2\)</span></p>
<h4 id="4_2">4.其他神经网络<a class="headerlink" href="#4_2" title="Permanent link">&para;</a></h4>
<p>RBF 网络：单隐层前馈神经网络, 它使用径向基函数作为隐层神经元激活函数, 而输出层则是隐层神经元输出的线性组合.
ART 网络：输出神经元一个激活其他全被抑制.</p>
<hr />
<h2 id="_8">第六章<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 支持向量机</h2>

<h4 id="1_3">1.间隔与支持向量<a class="headerlink" href="#1_3" title="Permanent link">&para;</a></h4>
<p>什么是支持向量？</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 支撑整个"道路"宽度的点</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 边缘点</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 满足 <span class="arithmatex">\(y_i(\bm{w}^T\bm{x}_i +b) = 1\)</span> 的点</li>
</ul>
<p>样本 <span class="arithmatex">\((\bm{x}_i,y_i)\)</span>, 其中 <span class="arithmatex">\(y_i = \pm 1\)</span>.</p>
<p>我们需要找到划分函数 <span class="arithmatex">\(\hat{y} = \bm{w}^T\bm{x} + b\)</span> 对样本进行分类</p>
<p>在离散的样本中，<span class="arithmatex">\(\hat{y} &gt; \theta_1\)</span> 为正例， <span class="arithmatex">\(\hat{y} &lt; \theta_2\)</span> 为正例,中间不希望有样本</p>
<p>临界线 <span class="arithmatex">\(\bm{w}^T\bm{x} + b = \theta_1\)</span>, <span class="arithmatex">\(\bm{w}^T\bm{x} + b = \theta_2\)</span>.</p>
<p>齐次归一临界线：<span class="arithmatex">\(\bm{w'}^T\bm{x} + b' = 1\)</span>, <span class="arithmatex">\(\bm{w'}^T\bm{x} + b' = -1\)</span>.</p>
<p>即在新的划分函数 <span class="arithmatex">\(\hat{y}&gt;1\)</span> 正例，<span class="arithmatex">\(\hat{y} &lt; -1\)</span> 反例.</p>
<p>寻找参数 <span class="arithmatex">\(\bm{w}\)</span> 和 <span class="arithmatex">\(b\)</span>,使得间隔 <span class="arithmatex">\(\gamma = \frac{2}{\|\bm{w}\|}\)</span> 最大，即求 <span class="arithmatex">\(\frac{\|\bm{w}\|}{2}\)</span>最小.</p>
<p>满足所有点划分正确 <span class="arithmatex">\(y_i(\bm{w}^T\bm{x}_i +b) \geq 1, i=1,2,\cdots,m\)</span>.</p>
<p><img alt="alt text" src="../img/%7BFD915AD6-8DC9-42BE-8ECE-A456B22D28DA%7D.png" /></p>
<h4 id="2_3">2.对偶问题<a class="headerlink" href="#2_3" title="Permanent link">&para;</a></h4>
<p>现在的问题：求 <span class="arithmatex">\(\frac{1}{2}\|\bm{w}\|\)</span> 最小值 <span class="arithmatex">\(\iff\)</span> 求 <span class="arithmatex">\(\frac{1}{2}\|\bm{w}\|^2\)</span> 最小值.
约束条件：<span class="arithmatex">\(y_i(\bm{w}^T\bm{x}_i +b) \geq 1\)</span> <span class="arithmatex">\(\iff\)</span> <span class="arithmatex">\(-(y_i(\bm{w}^T\bm{x}_i +b) - 1)\leq 0\)</span></p>
<h5 id="_9">拉格朗日乘子法<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h5>
<p>拉格朗日函数： <span class="arithmatex">\(L(\bm{w},b,\bm{\alpha}) = \frac{1}{2}\|\bm{w}\|^2 - \sum\limits_{i=1}^{m}\alpha_i\big(y_i(\bm{w}^T\bm{x}_i+b)-1\big)\)</span></p>
<p>分别对 <span class="arithmatex">\(\bm{w}\)</span> , <span class="arithmatex">\(b\)</span> 求偏导取零有：<span class="arithmatex">\(\bm{w} = \sum\limits_{i=1}^{m}\alpha_iy_i\bm{x}_i\)</span>,<span class="arithmatex">\(\sum\limits_{i=1}^{m}\alpha_iy_i = 0\)</span>.</p>
<p>问题转化为：<span class="arithmatex">\(\min\limits_{\alpha}\frac{1}{2}\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{m}\alpha_i\alpha_jy_iy_j\bm{x}_i^T\bm{x}_j -\sum\limits_{i=1}^{m}\alpha_i\)</span></p>
<p>最终模型：<span class="arithmatex">\(f(x) = \bm{w}^T\bm{x} + b = \sum\limits_{i=1}^{m}\alpha_i y_i \bm{x}_i^T\bm{x} + b\)</span></p>
<p><span class="arithmatex">\(KKT\)</span> 条件：</p>
<div class="arithmatex">\[\begin{cases}
\alpha_i \geq 0\\
y_if(\bm{x}_i) \geq 1\\
\alpha_i(y_if(\bm{x}_i) - 1) = 0
\end{cases}\]</div>
<p>解的稀疏性：<span class="arithmatex">\(y_if(\bm{x}_i) &gt; 1\)</span> 则 <span class="arithmatex">\(\alpha_i = 0\)</span> <span style = "background-color : #00bbffff">最终模型仅与支持向量有关</span></p>
<h5 id="smo">SMO<a class="headerlink" href="#smo" title="Permanent link">&para;</a></h5>
<p>现在的约束：<span class="arithmatex">\(\sum\limits_{i=1}^{m}\alpha_iy_i = 0\)</span></p>
<h6 id="_10">思路：<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h6>
<p>1.选取需要更新的变量 <span class="arithmatex">\(\alpha_i\)</span> 和 <span class="arithmatex">\(\alpha_j\)</span>
2.固定其他 <span class="arithmatex">\(\alpha\)</span> 参数</p>
<h4 id="3_2">3.核函数<a class="headerlink" href="#3_2" title="Permanent link">&para;</a></h4>
<p>无法找到能划分两类样本的超平面？
- [x] 映射高维空间
<img alt="alt text" src="../img/%7B86F840BF-24E4-4DD1-892F-A33B9CA9CDE1%7D.png" /></p>
<p>观察最终模型：<span class="arithmatex">\(f(x) = \bm{w}^T\bm{x} + b = \sum\limits_{i=1}^{m}\alpha_i y_i \bm{x}_i^T\bm{x} + b\)</span>,仅与内积有关.
所以将 <span class="arithmatex">\(\bm{x}\)</span> 映射为 <span class="arithmatex">\(\phi(\bm{x})\)</span> 也只和 <span class="arithmatex">\(\phi(\bm{x_i})^T\phi(\bm{x_j})\)</span> 有关</p>
<h5 id="31_2">3.1 基本想法<a class="headerlink" href="#31_2" title="Permanent link">&para;</a></h5>
<p>不显式设计核映射，而是设计核函数：<span class="arithmatex">\(\kappa(\bm{x}_i,\bm{x}_j) = \phi(\bm{x}_i)^T\phi(\bm{x}_j)\)</span>.</p>
<h5 id="32_2">3.2 常见核函数<a class="headerlink" href="#32_2" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th style="text-align: left;">名称</th>
<th style="text-align: left;">表达式</th>
<th style="text-align: left;">参数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>线性核</strong></td>
<td style="text-align: left;"><span class="arithmatex">\(\kappa(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i^T \mathbf{x}_j\)</span></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"><strong>多项式核</strong></td>
<td style="text-align: left;"><span class="arithmatex">\(\kappa(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i^T \mathbf{x}_j)^d\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(d \geq 1\)</span> 为多项式的次数</td>
</tr>
<tr>
<td style="text-align: left;"><strong>高斯核</strong></td>
<td style="text-align: left;"><span class="arithmatex">\(\kappa(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\frac{\|\mathbf{x}_i - \mathbf{x}_j\|^2}{2\sigma^2}\right)\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(\sigma &gt; 0\)</span> 为高斯核的带宽 (width)</td>
</tr>
<tr>
<td style="text-align: left;"><strong>拉普拉斯核</strong></td>
<td style="text-align: left;"><span class="arithmatex">\(\kappa(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\frac{\|\mathbf{x}_i - \mathbf{x}_j\|}{\sigma}\right)\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(\sigma &gt; 0\)</span></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Sigmoid核</strong></td>
<td style="text-align: left;"><span class="arithmatex">\(\kappa(\mathbf{x}_i, \mathbf{x}_j) = \tanh(\beta \mathbf{x}_i^T \mathbf{x}_j + \theta)\)</span></td>
<td style="text-align: left;"><span class="arithmatex">\(\tanh\)</span> 为双曲正切函数，<span class="arithmatex">\(\beta &gt; 0\)</span>，<span class="arithmatex">\(\theta &lt; 0\)</span></td>
</tr>
</tbody>
</table>
<h4 id="4_3">4.软间隔与正则化<a class="headerlink" href="#4_3" title="Permanent link">&para;</a></h4>
<p>还是难以找到线性可分？
- [x] 软间隔
- [x] 允许支持向量机有一些样本不满足约束
<img alt="alt text" src="../img/%7BD4978882-0F8A-45EE-80B2-DD1B426CBA75%7D.png" /></p>
<h5 id="41-01">4.1 0/1损失函数<a class="headerlink" href="#41-01" title="Permanent link">&para;</a></h5>
<p>最大化间隔同时，不满足约束的样本尽可能少 
<span class="arithmatex">\(\min\limits_{\bm{w},b}\frac{1}{2}\|\bm{w}\|^2 + C\sum\limits_{i=1}^{m}l_{0/1}\big(y_i(\bm{w}^T\phi(\bm{x}_i)+b)-1\big)\)</span></p>
<p><span class="arithmatex">\(l_{0/1} = \begin{cases}
1 &amp; z &lt; 0\\
0  &amp;othrewise
\end{cases}\)</span></p>
<h5 id="42_1">4.2 正则化<a class="headerlink" href="#42_1" title="Permanent link">&para;</a></h5>
<p>一般形式：
<span class="arithmatex">\(\min\limits_{f} \Omega(f) + C\sum\limits_{i=1}^{m}l(f(\bm{x}_i),y_i)\)</span>
前者：结构风险，描述模型的一些性质
后者：经验风险，描述模型和训练数据的契合度</p>
<h4 id="5_2">5.支持向量回归<a class="headerlink" href="#5_2" title="Permanent link">&para;</a></h4>
<p>允许模型输出和实际输出存在 <span class="arithmatex">\(2\epsilon\)</span> 偏差
<img alt="alt text" src="../img/%7BE78D9D82-69BD-44C0-99CF-47CDBCFA73B7%7D.png" />
落入中间 <span class="arithmatex">\(2\epsilon\)</span> 样本不计入损失</p>
<hr />
<h2 id="_11">第七章<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 贝叶斯分类器</h2>

<p>通过训练集概率分布预测 <span class="arithmatex">\(\bm{x}\)</span> 应该被分类到何处，建模 <span class="arithmatex">\(P(c|\bm{x})\)</span>.</p>
<h4 id="1_4">1.基本理论<a class="headerlink" href="#1_4" title="Permanent link">&para;</a></h4>
<p>将样本 <span class="arithmatex">\(\bm{x}\)</span> 分到第 <span class="arithmatex">\(i\)</span> 类的条件风险：<span class="arithmatex">\(R(c_i|\bm{x}) = \sum \limits_{j=1}^{N}\lambda_{ij}P(c_j|\bm{x})\)</span>
判定准则：<span class="arithmatex">\(h^*(\bm{x}) = \argmin \limits_{c\in \mathcal{Y}}R(c |\bm{x})\)</span>. <span style = "background-color : #00bbffff">  选择风险最小的分类 </span></p>
<p>策略？
- [ ]  判别式
- [x]  生成式</p>
<h4 id="2_4">2.贝叶斯定理<a class="headerlink" href="#2_4" title="Permanent link">&para;</a></h4>
<p>如何得到 <span class="arithmatex">\(P(c | \bm{x})\)</span> ？</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 已知 <span class="arithmatex">\(P(c)\)</span></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 求 <span class="arithmatex">\(P(\bm{x} |c)\)</span></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 使用贝叶斯定理: <span class="arithmatex">\(P(c|\bm{x}) = \frac{P(c)P(\bm{x}|c)}{P(\bm{x})}\)</span></li>
</ul>
<h4 id="3_3">3.极大似然估计<a class="headerlink" href="#3_3" title="Permanent link">&para;</a></h4>
<h5 id="31_3">3.1 什么是似然？<a class="headerlink" href="#31_3" title="Permanent link">&para;</a></h5>
<p>我们看到了数据（结果）。
我们猜测是某个参数（原因）导致了它。
我们评估这个原因（参数值）的“像然程度”或“合理程度”。</p>
<p>一个精辟的总结（来自统计学家罗纳德·费舍尔）：
|   |解释|
|---|---|
|概率|是固定参数、变化数据时的密度|
|似然 |是固定数据、变化参数时的函数|</p>
<h5 id="32_3">3.2 怎么计算？<a class="headerlink" href="#32_3" title="Permanent link">&para;</a></h5>
<p>假定 <span class="arithmatex">\(P(\bm{x}|c)\)</span> 具有确定的概率分布形式，且由参数 <span class="arithmatex">\(\theta_c\)</span> 唯一确定，利用训练集 <span class="arithmatex">\(D\)</span> 来估计 <span class="arithmatex">\(\theta_c\)</span>.</p>
<p><span class="arithmatex">\(D\)</span> 中<span style = "background-color: #00bbffff"> 第 <span class="arithmatex">\(c\)</span> 类样本 </span>(好瓜or坏瓜) 集合 <span class="arithmatex">\(D_c\)</span> 的似然估计为： <span class="arithmatex">\(P(D_c|\theta_c) = \prod\limits_{x\in D_c} P(\bm{x}|\theta_c)\)</span>.
取对数 <span class="arithmatex">\(\hat{\theta_c} = \argmax\limits_{\theta_c}LL(\theta_c)=\log P(D_c|\theta_c) = \sum\limits_{\bm{x}\in D_c}\log P(\bm{x}|\theta_c)\)</span>.
假设 <span class="arithmatex">\(d\)</span> 个属性相互独立 <span class="arithmatex">\(P(c|\bm{x})=\frac{P(c)P(\bm{x}|c)}{P(\bm{x})} = \frac{P(c)}{P(\bm{x})}\prod\limits_{i=1}^{d}P(x_i|c)\)</span>.
<span class="arithmatex">\(P(x)\)</span>  对所有类别相同，于是对于<span class="arithmatex">\(\bm{x}\)</span> 的预测：
<span class="arithmatex">\(h_nb(\bm{x})=\argmax \limits_{c\in \mathcal{Y}}P(c)\prod\limits_{i=1}^{d}P(x_i|c)\)</span>
其中 <span class="arithmatex">\(P(c) = \frac{|D_c|}{|D|}\)</span>, <span class="arithmatex">\(P(x_i|c) = \frac{|D_{c,x_i}|}{|D_c|}\)</span>
可以看到其实就是计算预测样本各个属性值在分类样本的占比乘积，然后选取最大的分类</p>
<h5 id="33_1">3.3 拉普拉斯修正<a class="headerlink" href="#33_1" title="Permanent link">&para;</a></h5>
<p>如果某个属性值在训练中没有出现过会出现0消除其他信息</p>
<p>令 <span class="arithmatex">\(N\)</span> 表示训练集 <span class="arithmatex">\(D\)</span> 中可能的类别数，<span class="arithmatex">\(N_i\)</span> 表示第 <span class="arithmatex">\(i\)</span> 个属性可能的取值数
<span class="arithmatex">\(\hat{P(c)} = \frac{|D_c| +1}{|D|+N}\)</span> , <span class="arithmatex">\(\hat{P}(x_i|c) = \frac{|D_{c,x_i}|+1}{|D_c|+N_i}\)</span></p>
<h4 id="4_4">4.半朴素贝叶斯<a class="headerlink" href="#4_4" title="Permanent link">&para;</a></h4>
<p>属性不一定满足"独立性假设"</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 独依赖估计</li>
</ul>
<p>假设每个属性在类别之外最多仅依赖一个其他属性
<span class="arithmatex">\(P(c|\bm{x})\propto P(c)\prod\limits_{i=0}^{d}P(x_i|c,pa_i)\)</span></p>
<p>两种常见的方法：
1.SPODE
假设所有属性都依赖同一属性，称为"超父"然后通过交叉验证等模型选择方法来确定超父属性.</p>
<p>2.TAN
以属性间的条件互信息为边的权重构建完全图，再利用最大帯权生成树算法，仅保留强相关属性间的依赖性
<img alt="alt text" src="../img/%7B5D106379-4C22-4589-B7FA-0480D1A8355A%7D.png" /></p>
<hr />
<h2 id="_12">第八章<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 集成学习</h2>

<h4 id="1_5">1.个体与集成<a class="headerlink" href="#1_5" title="Permanent link">&para;</a></h4>
<p>多个学习器，最后投票处最终结果
<img alt="alt text" src="../img/%7B5AA07356-D087-40D9-840C-C46D33C2FBC4%7D.png" />
- [x] 集成个体：好而不同</p>
<p>两大类：串行和并行</p>
<h5 id="11-boosting">1.1 串行-Boosting<a class="headerlink" href="#11-boosting" title="Permanent link">&para;</a></h5>
<p>每次调整训练数据的样本分布
下一次训练重点关照上一组错误率高的样本
组合的最终版各个学习器权重不一样(表现好者高)
<img alt="alt text" src="../img/%7B5D1D30E6-6928-4981-A6C3-818291F38233%7D.png" /></p>
<h5 id="12-adaboost">1.2 AdaBoost算法<a class="headerlink" href="#12-adaboost" title="Permanent link">&para;</a></h5>
<p>解决了什么？</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 下一组训练的权重分配问题,即构造出了 <span class="arithmatex">\(D_{t+1}\)</span></li>
</ul>
<p><img alt="alt text" src="../img/%7BC0DE2768-8D2E-40CC-8968-CC81F2488DAB%7D.png" /></p>
<p>最终 <span class="arithmatex">\(D_{t+1}\)</span> 基于 <span class="arithmatex">\(D_t\)</span> 如下：
<img alt="alt text" src="../img/%7BE9FDA2FE-AB07-4D7B-9771-A970A9B234FE%7D.png" /></p>
<p><strong>注意事项：</strong>
数据分布的学习：
- [x] 重赋权法
- [x] 重采样法</p>
<p>重启动，避免训练过程过早停止</p>
<p>偏差-方差：降低偏差，可对泛化性能相当弱的学习器构造出很强的集成</p>
<h5 id="13-bagging">1.3 并行-Bagging<a class="headerlink" href="#13-bagging" title="Permanent link">&para;</a></h5>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 个体学习器不存在强依赖关系</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 并行化生成</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 自助采样法</li>
</ul>
<h5 id="14-bagging">1.4 Bagging<a class="headerlink" href="#14-bagging" title="Permanent link">&para;</a></h5>
<p><strong>思路：</strong> 通过构建多个独立的模型，让它们投票或平均，从而获得更稳定、更可靠的预测。</p>
<p><img alt="alt text" src="../img/%7B5D85E858-A61B-4EF7-BE55-7B262C12D352%7D.png" /></p>
<p>1.从训练集 <span class="arithmatex">\(D\)</span> 中有放回地随机抽取 n 个样本，形成新的训练集 <span class="arithmatex">\(D_t\)</span></p>
<p>2.可使用包外预测：使用未采样的样本进行模型验证</p>
<h5 id="15">1.5 随机森林<a class="headerlink" href="#15" title="Permanent link">&para;</a></h5>
<p><strong>RF</strong> 是bagging的拓展变种</p>
<p>从根节点开始，递归地：</p>
<ol>
<li>
<p><strong>特征子集选择</strong>：从 p 个特征中随机选择 m 个特征（通常 m = √p 或 log₂(p)）</p>
</li>
<li>
<p><strong>最佳分裂点选择</strong>：从这 m 个特征中，选择最佳的分裂特征和分裂点（基于基尼指数或信息增益）</p>
</li>
<li>
<p><strong>节点分裂</strong>：将数据划分为两个子集</p>
</li>
<li>
<p><strong>递归构建</strong>：对每个子节点重复上述过程，直到：</p>
<ul>
<li>节点样本数小于阈值</li>
<li>深度达到最大值</li>
<li>节点纯度足够高</li>
</ul>
</li>
</ol>
<h4 id="2_5">2.结合策略<a class="headerlink" href="#2_5" title="Permanent link">&para;</a></h4>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 平均法</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 投票法</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 学习法</li>
</ul>
<h4 id="3_4">3.多样性<a class="headerlink" href="#3_4" title="Permanent link">&para;</a></h4>
<h5 id="31-">3.1 误差-分歧分解<a class="headerlink" href="#31-" title="Permanent link">&para;</a></h5>
<p><img alt="alt text" src="../img/%7B17E058A5-867E-4912-852E-477D3E60C5AA%7D.png" /></p>
<p>这个漂亮的式子显示:个体学习器精确性越高、多样性越大，则集成效果越好。称为误差-分歧分解</p>
<hr />
<h2 id="_13">第九章<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 聚类</h2>

<p><strong>—— 无监督学习</strong></p>
<h3 id="1_6">1.聚类<a class="headerlink" href="#1_6" title="Permanent link">&para;</a></h3>
<p><strong>目标：</strong> 将数据样本划分为若干个通常不相交的“簇”</p>
<h3 id="2_6">2.性能度量<a class="headerlink" href="#2_6" title="Permanent link">&para;</a></h3>
<p><strong>外部指标</strong>： 将聚类结果与某个“参考模型”(reference model) 进行比较如 Jaccard 系数，FM 指数，Rand 指数
<strong>内部指标</strong>： 直接考察聚类结果，无参考模型，如 DB 指数，Dunn 指数等</p>
<h4 id="21_2">2.1 外部指标<a class="headerlink" href="#21_2" title="Permanent link">&para;</a></h4>
<p><img alt="alt text" src="../img/%7B266999D7-61B6-4209-A708-EA391D44E9CF%7D.png" /></p>
<p><img alt="alt text" src="../img/%7B6E658648-E50C-4797-BFEE-8004D7D221B6%7D.png" /></p>
<h4 id="22_1">2.2 内部指标<a class="headerlink" href="#22_1" title="Permanent link">&para;</a></h4>
<p>直接考察聚类结果而不用任何参考模型
如 DB 指数，Dunn 指数等</p>
<p>指标：簇内距离越短，不同簇距离越长</p>
<p><img alt="alt text" src="../img/%7B4B4B3211-9D3C-4289-B00F-6D1CBAA817EA%7D.png" /></p>
<p><strong><em>聚类的好坏不存在绝对标准</em></strong></p>
<p>聚类本身没有好坏之分；当用于具体任务时，根据效果如何，有好坏之分</p>
<h3 id="3_5">3.常见的聚类方法<a class="headerlink" href="#3_5" title="Permanent link">&para;</a></h3>
<h4 id="31_4">3.1 原型聚类<a class="headerlink" href="#31_4" title="Permanent link">&para;</a></h4>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> k-means k均值聚类</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 学习向量量化（LVQ）</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 高斯混合聚类</li>
</ul>
<h5 id="311-k-means-k">3.1.1  k-means k均值聚类<a class="headerlink" href="#311-k-means-k" title="Permanent link">&para;</a></h5>
<p><strong>步骤：</strong>
Step1: 随机选取k个样本点作为簇中心
Step2: 将其他样本点根据其与簇中心的距离，划分给最近的簇Step3: 更新各簇的均值向量，将其作为新的簇中心
Step4: 若所有簇中心未发生改变，则停止；否则执行Step 2</p>
<h5 id="312">3.1.2 学习向量量化<a class="headerlink" href="#312" title="Permanent link">&para;</a></h5>
<p><img alt="alt text" src="../img/%7B11889E59-8093-4330-9D04-03DF01A72B32%7D.png" /></p>
<h4 id="32_4">3.2 密度聚类<a class="headerlink" href="#32_4" title="Permanent link">&para;</a></h4>
<p>划分多个等价类未必有簇中心</p>
<p>DBCSN：
<img alt="alt text" src="../img/%7B6B5F5814-D4B1-409F-85AE-476A86387375%7D.png" /></p>
<h4 id="33_2">3.3 层次聚类<a class="headerlink" href="#33_2" title="Permanent link">&para;</a></h4>
<p><strong>AGNES</strong></p>
<p><img alt="alt text" src="../img/%7B89532A51-FEA7-494D-8561-F631CF9B7A82%7D.png" /></p>
<hr />
<h2 id="_14">第十章<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 降维与度量学习</h2>

<h3 id="1k">1.k近邻学习<a class="headerlink" href="#1k" title="Permanent link">&para;</a></h3>
<p>要判断一个样本的类别，就看看它周围最近的K个邻居是什么类别，然后"随大流"。</p>
<p>出错率：<span class="arithmatex">\(P(err) = 1- \sum\limits_{c \in \mathcal{Y}}P(c|\bm{x})P(c|\bm{z})\)</span></p>
<p><img alt="alt text" src="../img/%7B0FAE27C8-E91F-47F9-A8AB-9A276E1A7EC8%7D.png" /></p>
<p>最近邻分类器虽简单，但它的泛化错误率不超过贝叶斯最优分类器的错误率的两倍</p>
<h3 id="2_7">2.低维嵌入<a class="headerlink" href="#2_7" title="Permanent link">&para;</a></h3>
<p>在高维情形下出现的数据样本稀疏、距离计算困难等问题</p>
<p><strong><em>降维</em></strong>
<img alt="alt text" src="../img/%7BA8CF2018-1C0D-43A7-9637-5741621FCE43%7D.png" /></p>
<p>多维缩放：
要求原始空间中样本之间的距离在低维空间中得以保持</p>
<p><img alt="alt text" src="../img/%7B8B76BAF9-7B6D-4151-BA69-5026F9DF3BA6%7D.png" /></p>
<p><img alt="alt text" src="../img/%7B6B5F8EA0-E705-43AD-9375-514F9F74589A%7D.png" /></p>
<p>由此即可通过降维前后保持不变的距离矩阵D求取内积矩阵B</p>
<h3 id="3_6">3.主成分分析<a class="headerlink" href="#3_6" title="Permanent link">&para;</a></h3>
<p>对于正交属性空间中的样本点，如何用一个超平面(直线的高维推广)对所有样本进行恰当的表达?</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 最近重构性：样本点到这个超平面的距离都足够近</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 最大可分性：样本点在这个超平面上的投影能尽可能分开</li>
</ul>
<p><strong>PCA</strong>
输入： 样本集，低维空间维数
算法：
1. 对所有样本进行中心化
2. 计算样本的协方差矩阵 <span class="arithmatex">\(X^TX\)</span>
3. 对协方差矩阵做特征值分解
4. 取最大的 <span class="arithmatex">\(d'\)</span> 个特征值所对应的特征向量 <span class="arithmatex">\(w_1,\cdots,w_{d'}\)</span></p>
<p>输出:投影矩阵 <span class="arithmatex">\(\bm{W} = (\bm{w_1,\cdots,w_{d'}}).\)</span></p>
<p>降维后低维空间的维数d′通常是由用户事先指定，或通过在d′值不同的低维空间中对k近邻分类器进行交叉验证来选取较好的d′值。对PCA，还可从重构的角度设置一个重构阔值，然后选取使下式成立的最小 <span class="arithmatex">\(d'\)</span> 值：
<img alt="alt text" src="../img/%7BB81A8453-F535-4020-9D90-7FD0C9D393C8%7D.png" /></p>
<p>$PCA $仅需保留 <span class="arithmatex">\(W\)</span>与样本的均值向量即可通过简单的向量减法和矩阵-向量乘法将新样本投影至低维空间中</p>
<h3 id="4_5">4. 核化线性降维<a class="headerlink" href="#4_5" title="Permanent link">&para;</a></h3>
<p><img alt="alt text" src="../img/%7B073FC50F-77AC-41BD-8352-D6DA8E36E7FA%7D.png" /></p>
<p><img alt="alt text" src="../img/%7B47D24F09-6BE1-4EF0-8B16-2515CD0D0307%7D.png" /></p>
<h3 id="5_3">5.流形学习<a class="headerlink" href="#5_3" title="Permanent link">&para;</a></h3>
<hr />
<h2 id="_15">第十一章<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 特征选择与稀疏学习</h2>

<h3 id="1_7">1. 特征选择<a class="headerlink" href="#1_7" title="Permanent link">&para;</a></h3>
<p>选择任务相关的特征子集</p>
<p><img alt="alt text" src="../img/%7B450914E6-24D1-4242-ADAB-FF6D404F720E%7D.png" /></p>
<p>关键点：子集搜索和子集评价</p>
<p>常见特征选择方法：
过滤式，包裹式，嵌入式</p>
<h4 id="11_1">1.1 过滤式选择<a class="headerlink" href="#11_1" title="Permanent link">&para;</a></h4>
<p>先用特征选择过程过滤原始数据，再用过滤后的特征来训练模型；特征选择过程与后续学习器无关</p>
<p><strong>Relief方法</strong> 二分类
选择相关统计量最大的特征</p>
<p>相关统计量：
<img alt="alt text" src="../img/%7B4A5C16BF-BF6E-40F6-A8DA-2983239EC77E%7D.png" />
即猜错近邻大，猜中近邻小的度量</p>
<h4 id="12_1">1.2 包裹式选择<a class="headerlink" href="#12_1" title="Permanent link">&para;</a></h4>
<p><strong>目的</strong> :就是为给定学习器选择最有利于其性能、“量身定做”的特征子集</p>
<p><strong><em>直接针对给定学习器进行优化</em></strong></p>
<p><strong>LVW:</strong>
1. 在循环的每一轮随机产生一个特征子集
2. 在随机产生的特征子集上通过交叉验证推断当前特征子集的误差
3. 进行多次循环，在多个随机产生的特征子集中选择误差最小的特征子集作为最终解*    </p>
<h4 id="13-l_1">1.3 嵌入式选择与 <span class="arithmatex">\(L_1\)</span> 正则化<a class="headerlink" href="#13-l_1" title="Permanent link">&para;</a></h4>
<p>嵌入式特征选择是将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，在学习器训练过程中自动地进行特征选择</p>
<p><img alt="alt text" src="../img/%7B659A3C90-BFE1-46A6-9FD3-A795422A0B44%7D.png" /></p>
<p><strong><em><span class="arithmatex">\(L_1\)</span> 范数更容易获得稀疏解</em></strong> 特征点更少</p>
<h3 id="2_8">2.稀疏表示与字典学习<a class="headerlink" href="#2_8" title="Permanent link">&para;</a></h3>
<p>为普通稠密表达的样本找到合适的字典，将样本转化为稀疏表示，这一过程称为字典学习</p>
<p><img alt="alt text" src="../img/%7BE389CE4D-0F88-4173-A5B4-479B6856600C%7D.png" /></p>
<p>k 允许非零元素的最大数量</p>
<h3 id="3_7">3. 压缩感知<a class="headerlink" href="#3_7" title="Permanent link">&para;</a></h3>
<p>能否利用接收到的压缩、丢包后的数字信号，精确重构出原信号?</p>
<hr />
<h2 id="_16">第十二章<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h2>
<h2 style="color: #2931d9ff; font-weight: normal;"> 半监督学习</h2>

<h3 id="1_8">1. 未标记样本<a class="headerlink" href="#1_8" title="Permanent link">&para;</a></h3>
<p>部分有标记部分无标记
<img alt="alt text" src="../img/%7BBB9FDF5F-9689-47F2-A71F-1E5FBC5B097F%7D.png" /></p>
<p>半监督学习：让学习器不依赖外界交互、自动地<strong>利用未标记样本来提升学习性能</strong>。</p>
<p><code>DeepSeek</code>：半监督学习就是用“少量昂贵的名师指导” + “大量免费的练习题”，来达到接近“全部名师指导”的效果，既省成本，效果又好</p>
<h3 id="2_9">2.生成式方法<a class="headerlink" href="#2_9" title="Permanent link">&para;</a></h3>
<h3 id="3svm">3.半监督SVM<a class="headerlink" href="#3svm" title="Permanent link">&para;</a></h3>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Sigmoid 函数 <span class="arithmatex">\(f(x) = \frac{1}{1+e^{-x}}\)</span> 的导数 <span class="arithmatex">\(f'(x) = f(x)(1-f(x))\)</span>&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.top", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>